{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "матрица путаницы \n",
      " [[235  27]\n",
      " [ 88  50]]\n",
      "мера ф1 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.80       262\n",
      "           1       0.65      0.36      0.47       138\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.69      0.63      0.63       400\n",
      "weighted avg       0.70      0.71      0.69       400\n",
      "\n",
      "точность \n",
      " 0.7125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"with open('text_classifier_ru_1', 'wb') as picklefile:\\n    pickle.dump(learn12,picklefile)\\nwith open('text_vectorizer_ru_1', 'wb') as picklefile:\\n    pickle.dump(vectorizer, picklefile)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import re\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#загрузка датасета\n",
    "with open('my_dataset_0.csv', 'r', newline='', encoding=\"utf-8\") as mydata:\n",
    "    reader = csv.DictReader(mydata, delimiter='#')\n",
    "    text=[]\n",
    "    category=[]\n",
    "    for row in reader:\n",
    "        text.append(row['text'])\n",
    "        category.append(int(row['target']))\n",
    "\n",
    "#предварительная обработка текста\n",
    "sp=spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "for i0 in range(0, len(text)):\n",
    "    #Убираем все \\n\n",
    "    #text[i0] = text[i0].replace(b'\\n', b' ')\n",
    "    text[i0] = text[i0].lower()\n",
    "    #лематизация\n",
    "    document=sp(text[i0])\n",
    "    document=[token.lemma_ for token in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    #убираем специальные знаки\n",
    "    document = re.sub(r'\\W', ' ', document)\n",
    "\n",
    "    #убираем лишние пробелы\n",
    "    document = re.sub(r'\\s+', ' ', document)\n",
    "    \n",
    "    text[i0]=document\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    encoding='utf-8',\n",
    "    min_df=4, \n",
    "    max_df=6, \n",
    "    ngram_range=(1,3),\n",
    ")\n",
    "tokens = vectorizer.fit_transform(text)\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "tokens = tfidfconverter.fit_transform(tokens)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tokens, category, test_size=0.2, random_state=0)\n",
    "\n",
    "# обучение модели\n",
    "learn12=DecisionTreeClassifier(\n",
    "    criterion = \"gini\",                     # criterion {“gini”, “entropy”, “log_loss”}\n",
    "    splitter = \"best\",                      # splitter {“best”, “random”},\n",
    "    min_samples_split = 2,                  # min_samples_split int or float,\n",
    "    min_weight_fraction_leaf = 0,           # int or float,\n",
    "    max_features = None,                    # max_featuresint, float или {“auto”, “sqrt”, “log2”} none,\n",
    "    min_impurity_decrease = 0.0,            # min_impurity_decrease float,\n",
    "    class_weight = None,                    # class_weight dict, list of dict or “balanced”, none\n",
    "    ccp_alpha = 0.0                         # ccp_alpha non-negative float\n",
    ") \n",
    "learn12.fit(x_train, y_train)\n",
    "\n",
    "# вывод результата\n",
    "pred = learn12.predict(x_test)\n",
    "print('матрица путаницы \\n', confusion_matrix(y_test,pred))\n",
    "print('мера ф1 \\n', classification_report(y_test,pred))\n",
    "print('точность \\n', accuracy_score(y_test, pred))\n",
    "\n",
    "# сохранение модели\n",
    "'''with open('text_classifier_ru_2', 'wb') as picklefile:\n",
    "    pickle.dump(learn12,picklefile)\n",
    "with open('text_vectorizer_ru_2', 'wb') as picklefile:\n",
    "    pickle.dump(vectorizer, picklefile)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_dataset_0.csv', 'r', newline='', encoding=\"utf-8\") as mydata:\n",
    "    reader = csv.DictReader(mydata, delimiter='#')\n",
    "    text=[]\n",
    "    category=[]\n",
    "    for row in reader:\n",
    "        text.append(row['text'])\n",
    "        category.append(int(row['target']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_files возвращает коллекцию, содержащую обучающие тексты и обучающие метки\n",
    "#reviews_train = load_files('C:/Users/Mihman/Desktop/TextClassification_1/txt_sentoken')\n",
    "# загружает файлы в x_train а метки в y_train\n",
    "\n",
    "sp=spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "for i0 in range(0, len(text)):\n",
    "    #Убираем все \\n\n",
    "    #text[i0] = text[i0].replace(b'\\n', b' ')\n",
    "    text[i0] = text[i0].lower()\n",
    "    #лематизация\n",
    "    document=sp(text[i0])\n",
    "    document=[token.lemma_ for token in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    #убираем специальные знаки\n",
    "    document = re.sub(r'\\W', ' ', document)\n",
    "\n",
    "    #убираем лишние пробелы\n",
    "    document = re.sub(r'\\s+', ' ', document)\n",
    "    \n",
    "    text[i0]=document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    encoding='utf-8',\n",
    "    min_df=4, \n",
    "    max_df=6, \n",
    "    ngram_range=(1,3),\n",
    ")\n",
    "tokens = vectorizer.fit_transform(text)\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "tokens = tfidfconverter.fit_transform(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "#Векторайзер другой\n",
    "vect=TfidfVectorizer(\n",
    "    min_df=4,\n",
    "    max_df=6, \n",
    "    ngram_range=(1,3),\n",
    "    input='content',\n",
    "    encoding='utf-8',\n",
    "    lowercase='true',\n",
    "    binary='false'\n",
    ")\n",
    "vect.fit(text)\n",
    "tokens=vect.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tokens, category, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=10000, multi_class='ovr', n_jobs=1,\n",
       "                   random_state=0, tol=1e-06)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn=LogisticRegression(\n",
    "    C=10, \n",
    "    random_state=0,\n",
    "    tol=1e-6,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs', #liblinear\n",
    "    multi_class='ovr',\n",
    "    n_jobs=1,\n",
    "    max_iter=10000\n",
    ")\n",
    "learn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "точность \n",
      " 0.605\n",
      "точность \n",
      " 0.7175\n",
      "точность \n",
      " 0.6475\n",
      "точность \n",
      " 0.4475\n",
      "точность \n",
      " 0.6975\n",
      "точность \n",
      " 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "learn0=KNeighborsClassifier()\n",
    "learn0.fit(x_train, y_train)\n",
    "\n",
    "learn1=DecisionTreeClassifier()\n",
    "learn1.fit(x_train, y_train)\n",
    "\n",
    "learn2=LinearDiscriminantAnalysis()\n",
    "learn2.fit(x_train.toarray(), y_train)\n",
    "\n",
    "learn3=GaussianNB()\n",
    "learn3.fit(x_train.toarray(), y_train)\n",
    "\n",
    "learn4=SVC()\n",
    "learn4.fit(x_train, y_train)\n",
    "\n",
    "learn5=LogisticRegression(C=10)\n",
    "learn5.fit(x_train, y_train)\n",
    "\n",
    "pred0 = learn0.predict(x_test)\n",
    "pred1 = learn1.predict(x_test)\n",
    "pred2 = learn2.predict(x_test)\n",
    "pred3 = learn3.predict(x_test.toarray())\n",
    "pred4 = learn4.predict(x_test)\n",
    "pred5 = learn5.predict(x_test)\n",
    "\n",
    "print('точность \\n', accuracy_score(y_test, pred0))\n",
    "print('точность \\n', accuracy_score(y_test, pred1))\n",
    "print('точность \\n', accuracy_score(y_test, pred2))\n",
    "print('точность \\n', accuracy_score(y_test, pred3))\n",
    "print('точность \\n', accuracy_score(y_test, pred4))\n",
    "print('точность \\n', accuracy_score(y_test, pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn12=DecisionTreeClassifier()\n",
    "learn12.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "матрица путаницы \n",
      " [[232  30]\n",
      " [ 87  51]]\n",
      "мера ф1 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80       262\n",
      "           1       0.63      0.37      0.47       138\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.68      0.63      0.63       400\n",
      "weighted avg       0.69      0.71      0.68       400\n",
      "\n",
      "точность \n",
      " 0.7075\n"
     ]
    }
   ],
   "source": [
    "pred = learn12.predict(x_test)\n",
    "print('матрица путаницы \\n', confusion_matrix(y_test,pred))\n",
    "print('мера ф1 \\n', classification_report(y_test,pred))\n",
    "print('точность \\n', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "матрица путаницы \n",
      " [[237  25]\n",
      " [ 95  43]]\n",
      "мера ф1 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.80       262\n",
      "           1       0.63      0.31      0.42       138\n",
      "\n",
      "    accuracy                           0.70       400\n",
      "   macro avg       0.67      0.61      0.61       400\n",
      "weighted avg       0.69      0.70      0.67       400\n",
      "\n",
      "точность \n",
      " 0.7\n"
     ]
    }
   ],
   "source": [
    "#Попытка исползовать ансамбль\n",
    "regr = BaggingClassifier(\n",
    "    base_estimator = LogisticRegression(\n",
    "        C=10, \n",
    "        random_state=0,\n",
    "        tol=1e-6,\n",
    "        penalty='l2',\n",
    "        solver='lbfgs', #liblinear\n",
    "        multi_class='ovr',\n",
    "        n_jobs=1,\n",
    "        max_iter=10000\n",
    "    ),\n",
    "    n_estimators=10,\n",
    "    random_state=0\n",
    ")\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "pred = regr.predict(x_test)\n",
    "print('матрица путаницы \\n', confusion_matrix(y_test,pred))\n",
    "print('мера ф1 \\n', classification_report(y_test,pred))\n",
    "print('точность \\n', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('text_classifier_ru_1', 'wb') as picklefile:\n",
    "    pickle.dump(learn,picklefile)\n",
    "with open('text_vectorizer_ru_1', 'wb') as picklefile:\n",
    "    pickle.dump(vectorizer, picklefile)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "939480ed579cbcc9bd95c0bb2f0a271d068ec362d36f1415ed941c7dadb52340"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
